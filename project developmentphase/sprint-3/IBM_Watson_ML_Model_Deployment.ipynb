COMPARING SOME FUNDAMENTAL REGRESSION METHODS ON ADMISSION PREDICTION DATA AND DEPLOYING ML MODEL TO IBM CLOUD
There are lots of regression methods to predict data such as Linear Regression, Decision Tree Regression and so on. In this notebook, we will try to predict the "Chance of Admit" data by using some of fundamental regression methods, which are Linear Regression, Multiple Linear Regression, Decision Tree Regression and Random Forest Regression.

Importing the required libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
%matplotlib inline
Preparing the dataset
import os, types
import pandas as pd
from botocore.client import Config
import ibm_boto3

def __iter__(self): return 0

# @hidden_cell
# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.
# You might want to remove those credentials before you share the notebook.
cos_client = ibm_boto3.client(service_name='s3',
    ibm_api_key_id='',
    ibm_auth_endpoint="https://iam.cloud.ibm.com/oidc/token",
    config=Config(signature_version='oauth'),
    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')

bucket = 'uaepmodeldeployment-donotdelete-pr-zuu1mvtpg1ntno'
object_key = 'Admission_Predict_Ver1.1.csv'

body = cos_client.get_object(Bucket=bucket,Key=object_key)['Body']
# add missing __iter__ method, so pandas accepts body as file-like object
if not hasattr(body, "__iter__"): body.__iter__ = types.MethodType( __iter__, body )

df = pd.read_csv(body)
df = df.iloc[:,1:]
df.head()
GRE Score	TOEFL Score	University Rating	SOP	LOR	CGPA	Research	Chance of Admit
0	337	118	4	4.5	4.5	9.65	1	0.92
1	324	107	4	4.0	4.5	8.87	1	0.76
2	316	104	3	3.0	3.5	8.00	1	0.72
3	322	110	3	3.5	2.5	8.67	1	0.80
4	314	103	2	2.0	3.0	8.21	0	0.65
Creating a correlation matrix
corr_matrix = df.corr()
corr_matrix
GRE Score	TOEFL Score	University Rating	SOP	LOR	CGPA	Research	Chance of Admit
GRE Score	1.000000	0.827200	0.635376	0.613498	0.524679	0.825878	0.563398	0.810351
TOEFL Score	0.827200	1.000000	0.649799	0.644410	0.541563	0.810574	0.467012	0.792228
University Rating	0.635376	0.649799	1.000000	0.728024	0.608651	0.705254	0.427047	0.690132
SOP	0.613498	0.644410	0.728024	1.000000	0.663707	0.712154	0.408116	0.684137
LOR	0.524679	0.541563	0.608651	0.663707	1.000000	0.637469	0.372526	0.645365
CGPA	0.825878	0.810574	0.705254	0.712154	0.637469	1.000000	0.501311	0.882413
Research	0.563398	0.467012	0.427047	0.408116	0.372526	0.501311	1.000000	0.545871
Chance of Admit	0.810351	0.792228	0.690132	0.684137	0.645365	0.882413	0.545871	1.000000
When looking at the data and correlation matrix, it seems that "Chance of Admit" values depend on lots of variables. To observe the effects of columns on "Chance of Admit" values in detail, so creating a correlation graph.

#plotting the correlation matrix as a heatmap

fig = plt.figure(figsize=(12,8))
sns.heatmap(corr_matrix,annot=True)
plt.show()

As seen, there are direct proportions between "Chance of Admit" data and the other columns. In order to observe these direct proportions more clearly, we will visualize the data.

#plotting data which have high correlation

sns.relplot(data=df,x="GRE Score",y="Chance of Admit ",hue="Research",
            palette="Set1",alpha=0.7)
plt.title("GRE Score vs Chance of Admit")
plt.show()

sns.relplot(data=df,x="CGPA",y="Chance of Admit ",hue="Research",
            palette="Set2",alpha=0.7)
plt.title("CGPA vs Chance of Admit")
plt.show()

sns.relplot(data=df,x="TOEFL Score",y="Chance of Admit ",hue="Research",
            palette="Set1",alpha=0.7,kind="line",ci=None)
plt.title("TOEFL Score vs Chance of Admit")
plt.show()

sns.barplot(data=df,x="SOP",y="Chance of Admit ",
            palette="Set2",hue="Research")
plt.title("SOP vs Chance of Admit")
plt.show()

sns.barplot(data=df,x="LOR ",y="Chance of Admit ",
            palette="Set3",hue="Research")
plt.title("LOR vs Chance of Admit")
plt.show()

sns.barplot(data=df,x="University Rating",y="Chance of Admit ",
            palette="Set1")
plt.title("University Rating vs Chance of Admit")
plt.show()

It was said that there are direct proportions between the columns and "Chance of Admit" data. Also, when observing the graphs, there are linear relationships between them. Therefore, using Linear Regression method may be suitable on the data, but since "Chance of Admit" data depends on more than one varible, it is more appropriate to imply Multiple Linear Regression method instead of Linear Regression method.

Importing the required libraries for regression analyzes
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
Spliting the dataset into training and testing data
x = df[["GRE Score","TOEFL Score","University Rating","SOP","LOR ","CGPA", "Research"]]
y = df["Chance of Admit "].values.reshape(-1,1)

x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)
MULTIPLE LINEAR REGRESSION
#implying multiple linear regression and determining its score

multiple_lin_reg = LinearRegression()
multiple_lin_reg.fit(x_train,y_train)

y_pred_mlr = multiple_lin_reg.predict(x_test)

r2_score_mlr = r2_score(y_test,y_pred_mlr)
print("Mutiple Linear Regression's Score = {:.3f}".format(r2_score_mlr))
Mutiple Linear Regression's Score = 0.819
DECISION TREE REGRESSION
#implying decision tree regression and determining its score

tree_reg = DecisionTreeRegressor()
tree_reg.fit(x_train,y_train)

y_pred_tree = tree_reg.predict(x_test)

r2_score_tree = r2_score(y_test,y_pred_tree)
print("Decision Tree Regression's Score = {:.3f}".format(r2_score_tree))
Decision Tree Regression's Score = 0.565
RANDOM FOREST REGRESSION
#implying random forest regression and determining its score

ran_for_reg = RandomForestRegressor(n_estimators=100,random_state=42)
ran_for_reg.fit(x_train,y_train)

y_pred_rfr = ran_for_reg.predict(x_test)

r2_score_rfr = r2_score(y_test,y_pred_rfr)
print("Random Forest Regression's Score = {:.3f}".format(r2_score_rfr))
Random Forest Regression's Score = 0.787
CONCLUSION
R^2 score is an indicator of accuracy of Regression Models, and the accuracy is measured as close to 1 of this value. Therefore, as seen, Multiple Linear Regression Model is better than Decision Tree Regression and Random Forest Regression on this dataset when comparing their R^2 scores.

!pip install ibm_watson_machine_learning
Requirement already satisfied: ibm_watson_machine_learning in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (1.0.257)
Requirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (1.26.7)
Requirement already satisfied: importlib-metadata in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (4.8.2)
Requirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (2.26.0)
Requirement already satisfied: pandas<1.5.0,>=0.24.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (1.3.4)
Requirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (2022.9.24)
Requirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (0.8.9)
Requirement already satisfied: ibm-cos-sdk==2.11.* in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (2.11.0)
Requirement already satisfied: packaging in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (21.3)
Requirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (0.3.3)
Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (0.10.0)
Requirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (2.11.0)
Requirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (2.11.0)
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk-core==2.11.0->ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (2.8.2)
Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas<1.5.0,>=0.24.2->ibm_watson_machine_learning) (2021.3)
Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas<1.5.0,>=0.24.2->ibm_watson_machine_learning) (1.20.3)
Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->ibm-cos-sdk-core==2.11.0->ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (1.15.0)
Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->ibm_watson_machine_learning) (3.3)
Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->ibm_watson_machine_learning) (2.0.4)
Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from importlib-metadata->ibm_watson_machine_learning) (3.6.0)
Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from packaging->ibm_watson_machine_learning) (3.0.4)
ESTABLISHING CONNECTION TO IBM WATSON ML SERVICE
from ibm_watson_machine_learning import APIClient
wml_credentials = {
    "url": "https://us-south.ml.cloud.ibm.com",
    "apikey": ""
}

client = APIClient(wml_credentials)
CREATING DEPLOYMENT SPACE
def guid_from_space_name(client, space_name):
    space = client.spaces.get_details()
    return (next(item for item in space['resources'] if item['entity']['name'] == space_name)['metadata']['id'])
space_uid = guid_from_space_name(client, 'Regression-Models')
print("Space UID = " + space_uid)
Space UID = a5d3879c-fce2-421a-a352-9e2bbb589332
client.set.default_space(space_uid)
'SUCCESS'
client.software_specifications.list()
-----------------------------  ------------------------------------  ----
NAME                           ASSET_ID                              TYPE
default_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base
kernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base
pytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base
scikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base
spark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base
pytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base
ai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base
shiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base
tensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base
pytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base
tensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base
autoai-kb_rt22.2-py3.10        125b6d9a-5b1f-5e8d-972a-b251688ccf40  base
runtime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base
scikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base
default_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base
pytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base
kernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base
pytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base
tensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base
spark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base
tensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base
runtime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base
do_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base
autoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base
tensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base
kernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base
pytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base
spark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base
pytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base
spark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base
spark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base
autoai-ts_rt22.2-py3.10        396b2e83-0953-5b86-9a55-7ce1628a406f  base
xgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base
pytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base
pytorch-onnx_rt22.2-py3.10     40e73f55-783a-5535-b3fa-0c8b94291431  base
default_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base
autoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base
autoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base
pmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base
spark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base
xgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base
pytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base
autoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base
spark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base
spark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base
autoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base
spss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base
cuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base
autoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base
pytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base
-----------------------------  ------------------------------------  ----
Note: Only first 50 records were displayed. To display more use 'limit' parameter.
PERSISTING THE MULTIPLE LINEAR REGRESSION MODEL AND DEPLOYING IT IN IBM CLOUD
#Set Python Version
software_spec_uid = client.software_specifications.get_uid_by_name("runtime-22.1-py3.9")
software_spec_uid
'12b83a17-24d8-5082-900f-0ab31fbfd3cb'
model_details = client.repository.store_model(model = multiple_lin_reg, meta_props={
    client.repository.ModelMetaNames.NAME: "UAEP_Multiple_Linear_Regression",
    client.repository.ModelMetaNames.TYPE: "scikit-learn_1.0",
    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid
}
)

model_id = client.repository.get_model_id(model_details)
model_id
'8083e827-e81f-40d1-84ab-20d511771869'
Testing
x_train
GRE Score	TOEFL Score	University Rating	SOP	LOR	CGPA
249	321	111	3	3.5	4.0	8.83
433	316	111	4	4.0	5.0	8.54
19	303	102	3	3.5	3.0	8.50
322	314	107	2	2.5	4.0	8.27
332	308	106	3	3.5	2.5	8.21
...	...	...	...	...	...	...
106	329	111	4	4.5	4.5	9.18
270	306	105	2	2.5	3.0	8.22
348	302	99	1	2.0	2.0	7.25
435	309	105	2	2.5	4.0	7.68
102	314	106	2	4.0	3.5	8.25
400 rows × 6 columns

multiple_lin_reg.predict(x_train)
array([[0.78452564],
       [0.75876324],
       [0.64981017],
       [0.68306325],
       [0.63503516],
       [0.56210158],
       [0.73893939],
       [0.79922576],
       [0.61772725],
       [0.69935177],
       [0.63731158],
       [0.95350643],
       [0.84155526],
       [0.97261308],
       [0.46824721],
       [0.8108055 ],
       [0.68040556],
       [0.88463178],
       [0.49097611],
       [0.67130182],
       [0.72944068],
       [0.88320461],
       [0.713287  ],
       [0.76639103],
       [0.68182838],
       [0.69961517],
       [0.58225445],
       [0.99253539],
       [0.83521168],
       [0.5140217 ],
       [0.72107234],
       [0.73687811],
       [0.83662906],
       [0.52331071],
       [0.821924  ],
       [0.50467988],
       [0.81795845],
       [0.96184185],
       [0.65432536],
       [0.68963298],
       [0.81432035],
       [0.62427772],
       [0.81414702],
       [0.5348331 ],
       [0.94850501],
       [0.66456131],
       [0.96389496],
       [0.80055016],
       [0.65387871],
       [0.73000169],
       [0.87276583],
       [0.66092095],
       [0.82556366],
       [0.73002343],
       [0.61005551],
       [0.58571441],
       [0.74066515],
       [0.80052026],
       [0.51782872],
       [0.6124432 ],
       [0.6771379 ],
       [0.75351877],
       [0.73827319],
       [0.50205802],
       [0.60500619],
       [0.64492726],
       [0.77920805],
       [0.60707001],
       [0.74564984],
       [0.91883799],
       [0.5406171 ],
       [0.63121408],
       [0.69669437],
       [0.48651781],
       [0.67695744],
       [0.78307965],
       [0.72777102],
       [0.64675406],
       [0.80075851],
       [0.56889969],
       [0.63835925],
       [0.68242234],
       [0.56249931],
       [0.7820103 ],
       [0.62829869],
       [0.88724382],
       [0.84705458],
       [0.72418815],
       [0.81969265],
       [0.5369417 ],
       [0.55844397],
       [0.53988981],
       [0.61186535],
       [0.46817797],
       [0.69924993],
       [0.79524516],
       [0.73306422],
       [0.56760432],
       [0.84108325],
       [0.52420251],
       [0.76591007],
       [0.87579389],
       [0.80296832],
       [0.80989185],
       [0.70750098],
       [0.74279057],
       [0.75264052],
       [0.77323957],
       [0.72392723],
       [0.57168642],
       [0.70515394],
       [0.7814642 ],
       [0.74163997],
       [0.70902417],
       [0.70085851],
       [0.52094513],
       [0.93828335],
       [0.55268794],
       [0.59488365],
       [0.88201119],
       [0.8325342 ],
       [0.5992875 ],
       [0.65254837],
       [0.62704566],
       [0.7863622 ],
       [0.74246114],
       [0.71574431],
       [0.67333064],
       [0.89992284],
       [0.63310683],
       [0.76661116],
       [0.75286149],
       [0.55661466],
       [0.70678347],
       [0.78162646],
       [0.51650277],
       [0.78025154],
       [0.61434095],
       [0.90475952],
       [0.79061621],
       [0.72246457],
       [0.69188515],
       [0.78023193],
       [0.73385645],
       [0.76864416],
       [0.71017673],
       [0.96733798],
       [0.51432994],
       [0.63536324],
       [0.65107113],
       [0.84147186],
       [0.7131132 ],
       [0.6055429 ],
       [0.69987734],
       [0.84849765],
       [0.63910871],
       [0.68070728],
       [0.83124043],
       [0.8214382 ],
       [0.80602078],
       [0.84947038],
       [0.65921397],
       [0.50842277],
       [0.59210023],
       [0.99631931],
       [0.53444738],
       [0.91222228],
       [0.85619959],
       [0.58226721],
       [0.65759306],
       [0.75813285],
       [1.007548  ],
       [0.7312767 ],
       [0.76675706],
       [0.87724383],
       [0.77942259],
       [0.58599856],
       [0.80573894],
       [0.95381001],
       [0.64997871],
       [0.70551423],
       [0.69194615],
       [0.65234152],
       [0.68240342],
       [0.92722999],
       [0.50721445],
       [0.76612103],
       [0.87238711],
       [0.47084686],
       [0.5446333 ],
       [0.66268527],
       [0.64291956],
       [0.80704478],
       [0.68581093],
       [0.64870349],
       [0.63496721],
       [0.82335677],
       [0.84614643],
       [0.85274679],
       [0.71636227],
       [0.78952305],
       [0.60158207],
       [0.84228948],
       [0.83474172],
       [0.6946515 ],
       [0.65091592],
       [0.79008795],
       [0.66835007],
       [0.77501096],
       [0.95408282],
       [0.6233115 ],
       [0.61197623],
       [0.78294368],
       [0.91134635],
       [0.73111549],
       [0.88594325],
       [0.58373715],
       [0.93646646],
       [0.6301446 ],
       [0.84889256],
       [0.80487076],
       [0.90487308],
       [0.87903371],
       [0.75552488],
       [0.80465553],
       [0.77304264],
       [0.7334947 ],
       [0.77982999],
       [0.72674788],
       [0.61560883],
       [0.52952522],
       [0.85236382],
       [0.84811207],
       [0.42557953],
       [0.6252595 ],
       [0.89470211],
       [0.72877524],
       [0.64605836],
       [0.73611386],
       [0.56367414],
       [0.60457721],
       [0.52394153],
       [0.63485831],
       [0.52346124],
       [0.64026173],
       [0.64950785],
       [0.71137398],
       [0.80855309],
       [0.60508472],
       [0.73084533],
       [0.84783365],
       [0.59753033],
       [0.64650439],
       [0.68448335],
       [0.76725784],
       [0.72574217],
       [0.68978059],
       [0.89847111],
       [0.96988588],
       [0.8851311 ],
       [0.9023154 ],
       [0.55234449],
       [0.90489549],
       [0.6262602 ],
       [0.96933192],
       [0.93154503],
       [0.66784305],
       [0.52756515],
       [0.69748004],
       [0.94145303],
       [0.49410436],
       [0.9019391 ],
       [0.72969728],
       [0.82967941],
       [0.78881734],
       [0.71418965],
       [0.93238178],
       [0.82315462],
       [0.62289906],
       [0.75456005],
       [0.81560925],
       [0.59636342],
       [0.55399858],
       [0.55750227],
       [0.59502025],
       [0.77228793],
       [0.60865921],
       [0.62859409],
       [0.66493022],
       [0.63148106],
       [0.64810602],
       [0.81538894],
       [0.86718228],
       [0.85326916],
       [0.69136913],
       [0.6290646 ],
       [0.64771949],
       [0.93772864],
       [0.85117871],
       [0.63421738],
       [0.97931981],
       [0.68094135],
       [0.47578308],
       [0.73115548],
       [0.76572476],
       [0.67284534],
       [0.73890912],
       [0.69121057],
       [0.70446433],
       [0.70080027],
       [0.49743102],
       [0.87112887],
       [0.81732316],
       [0.67194614],
       [0.84021452],
       [0.70278858],
       [0.91056019],
       [0.77059216],
       [0.69291598],
       [0.72896515],
       [0.80003692],
       [0.77270166],
       [0.78338054],
       [0.75688465],
       [0.60823988],
       [0.6284588 ],
       [0.51550402],
       [0.95267841],
       [0.74372776],
       [0.71968049],
       [0.7149125 ],
       [0.54046948],
       [0.77037709],
       [0.65568085],
       [0.73200361],
       [0.52830205],
       [0.75516797],
       [0.63250994],
       [0.62661634],
       [0.61646358],
       [0.67038916],
       [0.62732408],
       [0.57474207],
       [0.6622841 ],
       [0.78574867],
       [0.56818442],
       [0.88566066],
       [0.81049768],
       [0.77905378],
       [0.77898293],
       [0.81154681],
       [0.68146712],
       [0.64023369],
       [0.67001846],
       [0.53803367],
       [0.80501593],
       [0.87493467],
       [0.85241076],
       [0.99506685],
       [0.91640754],
       [0.60108556],
       [0.41483941],
       [0.80124583],
       [0.452612  ],
       [0.85415215],
       [0.69689159],
       [0.72476477],
       [0.58619845],
       [0.87022231],
       [0.58804488],
       [0.90342779],
       [0.84839052],
       [0.83034981],
       [0.98338309],
       [0.62213876],
       [0.60783387],
       [0.61995377],
       [0.75905704],
       [0.697583  ],
       [0.65471602],
       [0.96942667],
       [0.9105932 ],
       [0.67905083],
       [0.80295479],
       [0.94755128],
       [0.67797902],
       [0.66628343],
       [0.77191059],
       [0.92149435],
       [0.73009789],
       [0.93808074],
       [0.84646121],
       [0.60537451],
       [0.88670833],
       [0.96533678],
       [0.86256367],
       [0.63018033],
       [0.46955713],
       [0.59572775],
       [0.6723485 ]])
UAEP Multiple Linear Regression Model Deployment Test
import requests

# NOTE: you must manually set API_KEY below using information retrieved from your IBM Cloud account.
API_KEY = ""
token_response = requests.post('https://iam.cloud.ibm.com/identity/token', data={"apikey":
 API_KEY, "grant_type": 'urn:ibm:params:oauth:grant-type:apikey'})
mltoken = token_response.json()["access_token"]

header = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + mltoken}

# NOTE: manually define and pass the array(s) of values to be scored in the next line
payload_scoring = {"input_data": [{"field": [["GRE Score","TOEFL Score","University Rating","SOP","LOR ","CGPA", "Research"]], "values": [[326, 110, 2, 3.5, 4, 9.23, 1]]}]}

response_scoring = requests.post('https://us-south.ml.cloud.ibm.com/ml/v4/deployments/uaep_deployment/predictions?version=2022-11-12', json=payload_scoring,
 headers={'Authorization': 'Bearer ' + mltoken})
print("Scoring response")
print(response_scoring.json())
Scoring response
{'predictions': [{'fields': ['prediction'], 'values': [[[0.8448151378927107]]]}]}
probability = response_scoring.json()['predictions'][0]['values'][0][0][0]
probability
0.8448151378927107